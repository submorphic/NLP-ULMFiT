{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP ULMFiT fastai.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Hh8WiepMCqBg",
        "colab_type": "code",
        "outputId": "576ca7de-e87b-42f8-aad1-48ec1bfbb995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1227
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181201-cp36-cp36m-linux_x86_64.whl (576.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.3MB 31kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x632e8000 @  0x7fabffabd2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181201\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/67/8dd2051bb7dbde20ecca36215bd3e02ed436b976643078e3cdd41bd0256f/fastai-1.0.30-py3-none-any.whl (132kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fastai) (2017.11.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Collecting torchvision-nightly (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/bd/d0f9a33c81c79710eb7ee428b66869b49a8be16c7f1e446c211a7fbfb7be/torchvision_nightly-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.0.0)\n",
            "Requirement already satisfied: thinc==6.12.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (6.12.0)\n",
            "Collecting spacy==2.0.16 (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/39/288640f591b29aac6996c97ddfafc3262ae0be7513e06bc560921b112d7c/spacy-2.0.16-cp36-cp36m-manylinux1_x86_64.whl (23.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.3MB 1.1MB/s \n",
            "\u001b[?25hCollecting dataclasses (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 26.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 27.0MB/s \n",
            "\u001b[?25hCollecting fastprogress>=0.1.16 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/93/b35cabbab4d25a2fdc5cd196114fbe1160451df5cf1459a80781893f3b0f/fastprogress-0.1.16-py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.7)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.5.3)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.10.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (1.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchvision-nightly->fastai) (4.28.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied: preshed<3.0.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (2.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.4.3.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.6)\n",
            "Requirement already satisfied: dill<0.3.0,>=0.2.7 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.2.8.2)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.0.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "\u001b[31mspacy 2.0.16 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mspacy 2.0.16 has requirement regex==2018.01.10, but you'll have regex 2017.11.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision-nightly 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torchvision-nightly, spacy, dataclasses, numexpr, bottleneck, fastprogress, fastai\n",
            "  Found existing installation: spacy 2.0.17\n",
            "    Uninstalling spacy-2.0.17:\n",
            "      Successfully uninstalled spacy-2.0.17\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.30 fastprogress-0.1.16 numexpr-2.6.8 spacy-2.0.16 torchvision-nightly-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "37fyy0bsGVz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zbyHgZJuGepz",
        "colab_type": "code",
        "outputId": "f377eeed-faff-4643-b9bb-66a8c67a122c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EP0Y1_16GhFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_xQTHH-GjhQ",
        "colab_type": "code",
        "outputId": "a8087653-a885-4928-ef51-3c1f5336d1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "5WBolRyrGrMJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[df['label'].isin([1,10])]\n",
        "df = df.reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcYjHy9ZGvNz",
        "colab_type": "code",
        "outputId": "71d7103c-1506-43c2-b7ef-f2cb23c5c045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "1     584\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "_aCc4IffG0hY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZKdKhQLG1qQ",
        "colab_type": "code",
        "outputId": "6e2253b3-b7e7-4d5e-ef3d-092bb01784d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oY2UZ5-7G6Zb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tokenization \n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ETSkxV0G81S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXnTWtc1G-7z",
        "colab_type": "code",
        "outputId": "aec417cd-20a3-4977-a754-476563d24b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((710, 2), (474, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Me9l9dgzHI77",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ktgh9GEHNRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i34dzg2ZHRr9",
        "colab_type": "code",
        "outputId": "e1b035e4-7bd1-4147-ae2c-a50b894658b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "# train the learner object with learning rate = 1e-2\n",
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:08 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>7.845531</th>\n",
              "    <th>6.329831</th>\n",
              "    <th>0.140715</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5FH0c7JPHXZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylM-LCwVHaIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(data_clas, drop_mult=0.7)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POGYFwe_HdBN",
        "colab_type": "code",
        "outputId": "de371a7c-7c43-4060-c314-7d29990bd115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:34 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.507113</th>\n",
              "    <th>0.337310</th>\n",
              "    <th>0.883966</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FIlj9p-OHxBp",
        "colab_type": "code",
        "outputId": "6d711372-fce2-481f-b9a7-788fa1991b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "preds, targets = learn.get_preds()\n",
        "\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "pd.crosstab(predictions, targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>217</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      217   38\n",
              "1       17  202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}